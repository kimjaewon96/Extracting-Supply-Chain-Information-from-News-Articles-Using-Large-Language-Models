{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "import cleanco\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import disable_caching, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import set_seed, pipeline\n",
    "from itertools import combinations\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../modules'))\n",
    "from llm.context import LLMChatContext\n",
    "from llm.model import LLMModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = os.environ.get(\"ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If access token is not set, will raise an error. Look at the readme to obtain the access token.\n",
    "assert ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dba5ff270284e168b780d0832395ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "gen = LLMModel.from_transformers(\n",
    "    model_name,\n",
    "    model_kwargs={\"token\": ACCESS_TOKEN, \"max_length\": 4096},\n",
    "    tokenizer_kwargs={\"token\": ACCESS_TOKEN},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two stage Synthetic Data Generation\n",
    "## 1. Build synthetic relation triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_tree(company_name):\n",
    "    save_dict = {\"company_name\": company_name}\n",
    "    ctx = LLMChatContext(tokenizer=gen.tokenizer)\n",
    "    ctx.add_chat(\n",
    "        role=\"system\",\n",
    "        content=\"You are a helpful AI assistant with extensive knowledge of the global supply chain.\",\n",
    "    )\n",
    "    ctx.add_chat(\n",
    "        role=\"user\",\n",
    "        content=f\"Provide a detailed overview of the company '{company_name}'. Include information about the industry in which it operates and the specific products or services it offers. Limit your answer to a single paragraph.\",\n",
    "    )\n",
    "    company_info = ctx.generate(\n",
    "        gen=gen, generation_config={\"do_sample\": False, \"stop_strings\": \"\\n\"}\n",
    "    )\n",
    "    # Company info\n",
    "    ctx.add_chat(\n",
    "        role=\"user\",\n",
    "        content=f\"\"\"Your task is to identify related companies of '{company_name}' in its supply chain and categorize them according to the following relationship categories:\n",
    "\n",
    "- **Supplier companies:** These are companies that provide raw materials, components, or services to {company_name} for its production processes or operations. They are part of the upstream supply chain.\n",
    "\n",
    "- **Buyer companies:** These are companies that purchase products or services from {company_name}. They could be wholesalers, retailers, or end consumers in the downstream supply chain.\n",
    "\n",
    "- **Partnership companies:** These are companies that have strategic alliances, joint ventures, or collaborations with {company_name} for mutual benefit. These partnerships can involve co-development of products, shared resources, or other cooperative efforts.\n",
    "\n",
    "- **Ownership companies:** These are companies or entities that have a significant ownership stake in {company_name}. They might be parent companies, holding companies, or major shareholders.\n",
    "\n",
    "- **Subsidiary companies:** These are companies that are owned or controlled by {company_name}. They operate under the larger corporate umbrella of {company_name} and may engage in related or diverse business activities.\n",
    "\n",
    "Please provide your response in the JSON format below:\n",
    "```json\n",
    "{{\n",
    "  \"supplier_companies\": [...],\n",
    "  \"buyer_companies\": [...],\n",
    "  \"partnership_companies\": [...],\n",
    "  \"ownership_companies\": [...],\n",
    "  \"subsidiary_companies\": [...]\n",
    "}}\n",
    "```\n",
    "\n",
    "For each category, list only the names of actual, existing companies. Do not include organizations that are not companies (e.g., governments, universities, banks) or companies that are not directly part of the supply chain. If there are no companies that match a specific relationship category, still include the category name in the JSON output but leave the list empty. Also, for each category, do not write more than 3 companies.\"\"\",\n",
    "    )\n",
    "    response = ctx.generate(\n",
    "        prefill=\"```json\\n\",\n",
    "        gen=gen,\n",
    "        generation_config={\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.95,\n",
    "            \"stop_strings\": \"}\",\n",
    "        },\n",
    "    )\n",
    "    try:\n",
    "        obj = ast.literal_eval(response + \"}\")\n",
    "        assert all([x in obj for x in [\"supplier_companies\", \"buyer_companies\", \"partnership_companies\", \"ownership_companies\", \"subsidiary_companies\"]])\n",
    "        for key in [\"supplier_companies\", \"buyer_companies\", \"partnership_companies\", \"ownership_companies\", \"subsidiary_companies\"]:\n",
    "            temp_list = obj[key]\n",
    "            temp_list = [\n",
    "                re.sub(r\"\\([^)]*\\)\", \"\", x).strip() for x in temp_list\n",
    "            ]\n",
    "            temp_list = [cleanco.basename(x).strip() for x in temp_list]\n",
    "            temp_list = [x for x in temp_list if x]\n",
    "            save_dict[key] = temp_list\n",
    "        return save_dict, (company_name, company_info)\n",
    "    except Exception:\n",
    "        raise Exception\n",
    "    finally:\n",
    "        del ctx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1975d968c4e84296918bb2a9465eced5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68689554b8994337ac3bcc30869247ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c25d9823cf44ff80678ea96d73bbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "stage_one_results = []\n",
    "seed_companies = [\"Tesla\", \"Boeing\"]\n",
    "company_info_obj = {}\n",
    "\n",
    "for round in range(3):\n",
    "    seed_candidates = []\n",
    "    for idx, company in enumerate(tqdm(seed_companies)):\n",
    "        #print(company)\n",
    "        try:\n",
    "            company_dict, company_info_tuple = company_tree(company)\n",
    "            stage_one_results.append(company_dict)\n",
    "            company_info_obj[company_info_tuple[0]] = company_info_tuple[1]\n",
    "            seed_candidates += (\n",
    "                company_dict[\"supplier_companies\"]\n",
    "                + company_dict[\"buyer_companies\"]+ company_dict[\"partnership_companies\"]\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "        if (idx + 1) % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            sleep(15)\n",
    "    seed_candidates = list(set(seed_candidates))\n",
    "    seed_companies = [\n",
    "        x\n",
    "        for x in seed_candidates\n",
    "        if x not in company_info_obj.keys()\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_triples = []\n",
    "for row in stage_one_results:\n",
    "    bag = []\n",
    "    if not row['company_name']:\n",
    "        continue\n",
    "    for c in row['supplier_companies']:\n",
    "        if c == row['company_name']:\n",
    "            continue\n",
    "        elif c <= row['company_name']:\n",
    "            bag.append((c, row['company_name'], 2))\n",
    "        else:\n",
    "            bag.append((row['company_name'], c, 1))\n",
    "    for c in row['buyer_companies']:\n",
    "        if c == row['company_name']:\n",
    "            continue\n",
    "        elif c <= row['company_name']:\n",
    "            bag.append((c, row['company_name'], 1))\n",
    "        else:\n",
    "            bag.append((row['company_name'], c, 2))\n",
    "    for c in row['partnership_companies']:\n",
    "        if c == row['company_name']:\n",
    "            continue\n",
    "        elif c <= row['company_name']:\n",
    "            bag.append((c, row['company_name'], 3))\n",
    "        else:\n",
    "            bag.append((row['company_name'], c, 3))\n",
    "    for c in row['ownership_companies'] + row['subsidiary_companies']:\n",
    "        if c == row['company_name']:\n",
    "            continue\n",
    "        elif c <= row['company_name']:\n",
    "            bag.append((c, row['company_name'], 4))\n",
    "        else:\n",
    "            bag.append((row['company_name'], c, 4))\n",
    "    bag = list(set(bag))\n",
    "    relation_triples += bag\n",
    "relation_triples = list(set(relation_triples))\n",
    "\n",
    "df_relation_triples = pd.DataFrame(relation_triples, columns=[\"A\", \"B\", \"label\"])\n",
    "df_relation_triples.to_json(\"df_relation_triples.json\", orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 336, 2: 302, 1: 295, 3: 283})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([x[2] for x in relation_triples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Zero-shot Synthetic Sentences from Relation Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = dict()\n",
    "\n",
    "def get_company_info(company_name, info):\n",
    "    if info:\n",
    "        info_dict[company_name] = info\n",
    "        return info\n",
    "    if company_name in info_dict:\n",
    "        return info_dict[company_name]\n",
    "    ctx = LLMChatContext(tokenizer=gen.tokenizer)\n",
    "    ctx.add_chat(\n",
    "        role=\"system\",\n",
    "        content=\"You are a helpful AI assistant with extensive knowledge of the global supply chain.\",\n",
    "    )\n",
    "    ctx.add_chat(\n",
    "        role=\"user\",\n",
    "        content=f\"Provide a detailed overview of the company '{company_name}'. Include information about the industry in which it operates and the specific products or services it offers. Limit your answer to a single paragraph.\",\n",
    "    )\n",
    "    # Company info\n",
    "    result = ctx.generate(\n",
    "        gen=gen, generation_config={\"do_sample\": False, \"stop_strings\": \"\\n\"}\n",
    "    )\n",
    "    del ctx\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_sentences(A: str, B: str, label: int):\n",
    "    # swap\n",
    "    if random.random() > 0.5:\n",
    "        C = A\n",
    "        A = B\n",
    "        B = C\n",
    "        if label == 2:\n",
    "            label = 1\n",
    "        elif label == 1:\n",
    "            label = 2\n",
    "    save_dict = {\"A\": A, \"B\": B, \"label\": label, \"sentences\": []}\n",
    "    ctx = LLMChatContext(tokenizer=gen.tokenizer)\n",
    "    ctx.add_chat(\n",
    "        role=\"system\",\n",
    "        content=\"\"\"You are a helpful AI assistant with extensive knowledge of the global supply chain. Your task is to generate a realistic yet unique sentence that matches the given context.\"\"\",\n",
    "    )\n",
    "    # ctx.add_chat(\n",
    "    #     role=\"user\",\n",
    "    #     content=f\"Before generating the sentence, provide a detailed overview of the company '{A}'. Include information about the industry in which it operates and the specific products or services it offers. Limit your answer to a single paragraph.\",\n",
    "    # )\n",
    "    # ctx.add_chat(role=\"assistant\", content=get_company_info(A, None))\n",
    "    # ctx.add_chat(\n",
    "    #     role=\"user\",\n",
    "    #     content=f\"Next, provide a detailed overview of the company '{B}'. Include information about the industry in which it operates and the specific products or services it offers. Limit your answer to a single paragraph.\",\n",
    "    # )\n",
    "    # ctx.add_chat(role=\"assistant\", content=get_company_info(B, None))\n",
    "    match label:\n",
    "        case 1:\n",
    "            user_prompt = f\"Generate three different sentences that imply a buyer-supplier relationship between {A} and {B}, where {A} is the buyer and {B} is the supplier. Note that the sentences should not portray an ambiguous partnership relationship between {A} and {B}. The sentences should portray a clear indication of a directed supply chain relationship, such as expressing the items that are bought by {A} from {B}.\"\n",
    "        case 2:\n",
    "            user_prompt = f\"Generate three different sentences that imply a supplier-buyer relationship between {A} and {B}, where {A} is the supplier and {B} is the buyer. Note that the sentences should not portray an ambiguous partnership relationship between {A} and {B}. The sentences should portray a clear indication of a directed supply chain relationship, such as expressing the items that are shipped by {A} to {B}.\"\n",
    "        case 3:\n",
    "            user_prompt = f\"Generate three different sentences that imply a relationship between {A} and {B} that is portrayed as arbitrary or undirected. This relationship can take various forms, such as collaborations, joint ventures, strategic alliances, or any other type of ambiguous business relationship. Note that the sentences should not convey a supply chain relationship between the two companies.\"\n",
    "        case 4:\n",
    "            user_prompt = f\"Generate three different sentences that imply an ownership relationship between {A} and {B}, where {A} owns or has acquired {B}.\"\n",
    "    user_prompt += f\"\"\"The sentences should meet the following criteria:\n",
    "- Crafted in a style that could be reminiscent of a newspaper article, press release, industry report, or any other relevant source.\n",
    "- Contain the exact entity words '{A}' and '{B}'.\n",
    "- Should be unique, diverse and creative.\n",
    "\n",
    "Please provide your response in the JSON format below:\n",
    "```json\n",
    "{{\n",
    "    \"sentences\": [\"(sentence 1)\", \"(sentence 2)\", \"(sentence 3)\"]\n",
    "}}\n",
    "```\"\"\"\n",
    "    ctx.add_chat(role=\"user\", content=user_prompt)\n",
    "    response = ctx.generate(\n",
    "        prefill=\"```json\\n\",\n",
    "        gen=gen,\n",
    "        generation_config={\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.95,\n",
    "            \"stop_strings\": \"}\",\n",
    "        },\n",
    "    )\n",
    "    try:\n",
    "        obj = ast.literal_eval(response + \"}\")\n",
    "        save_dict[\"sentences\"] = obj[\"sentences\"]\n",
    "    except Exception:\n",
    "        print(\"!\")\n",
    "    finally:\n",
    "        del ctx\n",
    "        return save_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b25d6b70d7a45b388de25a1981c0a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "stage_two_results = []\n",
    "for idx, row in tqdm(df_relation_triples.iterrows(), total=len(df_relation_triples)):\n",
    "    stage_two_results.append(generate_sentences(A=row[\"A\"], B=row[\"B\"], label=row['label']))\n",
    "    pd.DataFrame(stage_two_results).to_json(\"2.Two stage.json\", orient=\"records\", force_ascii=False)\n",
    "    if (idx + 1) % 5 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.unload()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_parentheses(row):\n",
    "    row[\"original_text\"] = re.sub(r'\\(.*?\\)|\\[.*?\\]|<.*?>|\\{.*?\\}', '', row[\"original_text\"])\n",
    "    row[\"original_text\"] = re.sub(r'\\s{2,}', ' ', row[\"original_text\"]).strip()\n",
    "    return row\n",
    "\n",
    "def text_generator(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield row[\"original_text\"]\n",
    "\n",
    "def process_named_entities(df, ner_pipeline):\n",
    "    results = []\n",
    "    for output in tqdm(ner_pipeline(text_generator(df), aggregation_strategy=\"first\", batch_size=256)):\n",
    "        org_entities = [x for x in output if x['entity_group'] == 'ORG']\n",
    "        results.append(org_entities if len(org_entities) >= 2 else [])\n",
    "    return results\n",
    "\n",
    "def create_entity_pairs(df, ner_results):\n",
    "    entity_pairs = []\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        output = ner_results[idx]\n",
    "        for token_idx_from, token_idx_to in combinations(range(len(output)), r=2):\n",
    "            pair = create_entity_pair(row, output, token_idx_from, token_idx_to)\n",
    "            entity_pairs.append(pair)\n",
    "    return entity_pairs\n",
    "\n",
    "def create_entity_pair(row, entities, idx_from, idx_to):\n",
    "    pair = {\n",
    "        \"original_text\": row['original_text'],\n",
    "        \"label\": None,\n",
    "        \"NE_FROM\": None,\n",
    "        \"NE_TO\": None,\n",
    "        \"NE_OTHER\": [],\n",
    "        \"masked_text\": row[\"original_text\"]\n",
    "    }\n",
    "\n",
    "    for token_idx, token in reversed(list(enumerate(entities))):\n",
    "        if token_idx == idx_to:\n",
    "            pair[\"NE_TO\"] = token['word']\n",
    "            pair[\"masked_text\"] = pair[\"masked_text\"][:token['start']] + \"__NE_TO__\" + pair[\"masked_text\"][token['end']:]\n",
    "        elif token_idx == idx_from:\n",
    "            pair[\"NE_FROM\"] = token['word']\n",
    "            pair[\"masked_text\"] = pair[\"masked_text\"][:token['start']] + \"__NE_FROM__\" + pair[\"masked_text\"][token['end']:]\n",
    "        else:\n",
    "            pair[\"NE_OTHER\"].append(token['word'])\n",
    "            pair[\"masked_text\"] = pair[\"masked_text\"][:token['start']] + \"__NE_OTHER__\" + pair[\"masked_text\"][token['end']:]\n",
    "\n",
    "    pair['label'] = determine_label(row, pair[\"NE_FROM\"], pair[\"NE_TO\"])\n",
    "    return pair\n",
    "\n",
    "def determine_label(row, ne_from, ne_to):\n",
    "    if ne_from == row['A'] and ne_to == row['B']:\n",
    "        return row['label']\n",
    "    elif ne_from == row['B'] and ne_to == row['A']:\n",
    "        if row['label'] == 1:\n",
    "            return 2\n",
    "        elif row['label'] == 2:\n",
    "            return 1\n",
    "        else:\n",
    "            return row['label']\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118e61153db144a88461c452b806bbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1655c4d3a245437ea9c4e5c166f62d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6a5e2d790d42cfa80a0d18a9f0f1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(stage_two_results)\n",
    "df = df.explode(\"sentences\").dropna().reset_index(drop=True)\n",
    "df = df.rename(columns={\"sentences\": \"original_text\"})\n",
    "df = df.apply(strip_parentheses, axis=1)\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-large-NER\", device=\"cuda\")\n",
    "ner_results = process_named_entities(df, ner_pipeline)\n",
    "entity_pairs = create_entity_pairs(df, ner_results)\n",
    "final_df = pd.DataFrame(entity_pairs)\n",
    "final_df = final_df.groupby('original_text').filter(\n",
    "    lambda x: (x['NE_FROM'] != '').all() and\n",
    "              (x['NE_TO'] != '').all() and\n",
    "              (x['label'] != 0).any()\n",
    ").reset_index(drop=True)\n",
    "Dataset.from_pandas(final_df).save_to_disk(\"../../datasets/TwoStageDataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
